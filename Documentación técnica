DOCUMENTACIÃ“N TÃ‰CNICA
Semantic Security Gateway Firewall (SSGF)

VersiÃ³n actual: v0.x (basado en llm-entropy-filter + Gate + Escalado por AmbigÃ¼edad)

1ï¸âƒ£ VisiÃ³n General

SSGF es un firewall semÃ¡ntico para sistemas LLM, diseÃ±ado para:

Filtrar entrada antes del modelo

Clasificar intenciÃ³n

Detectar ambigÃ¼edad maliciosa

Escalar dinÃ¡micamente a anÃ¡lisis profundo

Reducir costo computacional

Actuar como middleware proxy independiente del modelo

No es un prompt.
Es una arquitectura de decisiÃ³n multinivel.

2ï¸âƒ£ Arquitectura General
Client
   â”‚
   â–¼
SSGF Proxy Middleware
   â”‚
   â”œâ”€â”€ Fast Pipeline (determinista local)
   â”‚       â”œâ”€ NormalizaciÃ³n
   â”‚       â”œâ”€ Hard triggers
   â”‚       â”œâ”€ Entropy scoring
   â”‚       â”œâ”€ Intention heuristics
   â”‚       â””â”€ Action: ALLOW | WARN | BLOCK | ESCALATE
   â”‚
   â””â”€â”€ Deep Pipeline (LLM / anÃ¡lisis contextual)
           â”œâ”€ Prompt Bench
           â”œâ”€ Ambiguity detection
           â”œâ”€ Semantic intent evaluation
           â””â”€ Final decision override
   â”‚
   â–¼
LLM / Backend protegido

3ï¸âƒ£ Modos Operativos
ğŸ”¹ MODE: FAST

100% local

Determinista

<1msâ€“5ms

Sin costo API

Usa rulesets JSON

Ideal para:

Proxy high-throughput

ModeraciÃ³n bÃ¡sica

API pÃºblicas

ğŸ”¹ MODE: DEEP

Se activa por:

score > threshold_warn

ambigÃ¼edad detectada

patrÃ³n sospechoso no concluyente

Usa LLM barato (ej: gpt-4o-mini)

Analiza:

intenciÃ³n real

contexto implÃ­cito

ingenierÃ­a social

Puede:

confirmar BLOCK

degradar a WARN

permitir con anotaciÃ³n

ğŸ”¹ MODE: HYBRID (recomendado)

Fast first â†’ Escalado inteligente â†’ Deep only if needed.

4ï¸âƒ£ Pipeline FAST
4.1 NormalizaciÃ³n

ConfiguraciÃ³n tÃ­pica:

{
  "lowercase": true,
  "trim": true,
  "collapse_whitespace": true,
  "unicode_nfkc": true
}

4.2 Hard Triggers

Tipos:

shouting

spam_keywords

phishing_patterns

credential_extraction

social_engineering_markers

Cada trigger:

{
  id,
  type,
  weight,
  pattern | detector
}

4.3 Entropy Score

Score final = suma ponderada de:

seÃ±ales estructurales

densidad keywords

anomalÃ­as sintÃ¡cticas

patrones de manipulaciÃ³n

Resultado:

entropy_score: 0.0 â€“ 1.0

4.4 Intention Evaluation (heurÃ­stico)

Clasificaciones actuales:

marketing_spam

phishing_attempt

credential_harvest

prompt_injection

jailbreak_attempt

unknown

safe

Devuelve:

{
  intention,
  confidence,
  rationale
}

4.5 DecisiÃ³n Local
Score	AcciÃ³n
< warn	ALLOW
warnâ€“block	WARN
> block	BLOCK
ambiguous	ESCALATE
5ï¸âƒ£ Pipeline DEEP
ActivaciÃ³n por AmbigÃ¼edad

Ejemplo clÃ¡sico:

â€œEnvÃ­ame tu cÃ³digo de verificaciÃ³nâ€

LingÃ¼Ã­sticamente correcto.
SemÃ¡nticamente peligroso.

5.1 Prompt Bench

Plantilla controlada:

You are a semantic security evaluator.
Classify the real-world intention behind this message.
Detect phishing, credential extraction, manipulation.
Return JSON only.


Salida estructurada:

{
  "intention": "...",
  "risk": 0.0-1.0,
  "justification": "...",
  "confidence": 0.0-1.0
}

5.2 Override System

Deep puede:

elevar WARN â†’ BLOCK

bajar BLOCK â†’ WARN

permitir con log

6ï¸âƒ£ Proxy Middleware

SSGF puede correr como:

ğŸ”¹ Express Middleware
app.post("/chat", ssgfMiddleware, forwardToLLM)

ğŸ”¹ Reverse Proxy
Client â†’ SSGF â†’ OpenAI

ğŸ”¹ SDK Embeddable
gate(text, { ruleset })

7ï¸âƒ£ DiseÃ±o de Decisiones

Modelo conceptual:

Riesgo = SeÃ±al estructural + IntenciÃ³n + AmbigÃ¼edad


Principios:

Determinismo primero

LLM solo si necesario

Cost-aware escalation

JSON-first outputs

Override explicable
